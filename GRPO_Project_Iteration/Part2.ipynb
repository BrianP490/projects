{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg4EjgNMYmSn"
      },
      "source": [
        "**Part 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8F-BVwxNvrC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D4bl4-xNwvl"
      },
      "outputs": [],
      "source": [
        "# Define the neural network\n",
        "class LogicNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogicNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 4)  # Input layer -> Hidden Layer\n",
        "        self.fc2 = nn.Linear(4, 1)  # Hidden Layer -> Output Layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50L6eW4tNxrC"
      },
      "outputs": [],
      "source": [
        "# Define the environment\n",
        "class LogicGateEnv:\n",
        "    def __init__(self, gate=\"AND\"):\n",
        "        self.gate = gate\n",
        "        self.data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "        self.targets = self.get_targets(gate)\n",
        "\n",
        "    def get_targets(self, gate):\n",
        "        if gate == \"AND\":\n",
        "            return torch.tensor([[0], [0], [0], [1]], dtype=torch.float32)\n",
        "        elif gate == \"OR\":\n",
        "            return torch.tensor([[0], [1], [1], [1]], dtype=torch.float32)\n",
        "        elif gate == \"XOR\":\n",
        "            return torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
        "        elif gate == \"XNOR\":\n",
        "            return torch.tensor([[1], [0], [0], [1]], dtype=torch.float32)\n",
        "\n",
        "    def step(self, input_idx, prediction):\n",
        "        correct = self.targets[input_idx].item()\n",
        "        # Rounds up to 1 if it is >=.5 to get prediction; else 0\n",
        "        reward = 1.0 if round(prediction.item()) == correct else -1.0\n",
        "        return reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRGKeCcJUWLU"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train_logic_gate(gate=\"XOR\", epochs=1000, learning_rate=0.01, batch_size=10):\n",
        "    print(f\"Training {gate} gate with {epochs} epochs, {learning_rate} learning rate, and {batch_size} batch size.\")\n",
        "    # Global stack\n",
        "    env = LogicGateEnv(gate)\n",
        "    net = LogicNet()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    num_correct = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Create Lists\n",
        "        rewards_batch = []\n",
        "        inputs_batch = []\n",
        "        targets_batch = []\n",
        "        prediction_batch = []\n",
        "        # Gather agent predictions in a loop, push values to lists :\n",
        "        for i in range(batch_size):\n",
        "            # Get model inputs and target\n",
        "            idx = random.randint(0, 3)\n",
        "            inputs = env.data[idx]\n",
        "            target = env.targets[idx]\n",
        "\n",
        "            # Get model prediction\n",
        "            prediction = net(inputs)\n",
        "\n",
        "            # Calculate reward\n",
        "            reward = env.step(idx, prediction)\n",
        "\n",
        "            # Append to lists\n",
        "            inputs_batch.append(inputs)\n",
        "            prediction_batch.append(prediction)\n",
        "            rewards_batch.append(reward)\n",
        "            targets_batch.append(target)\n",
        "\n",
        "        # Convert collected batch lists into PyTorch tensors\n",
        "        inputs_batch_tensor = torch.stack(inputs_batch)\n",
        "        prediction_batch_tensor = torch.stack(prediction_batch)\n",
        "        targets_batch_tensor = torch.stack(targets_batch)\n",
        "        rewards_batch_tensor = torch.tensor(rewards_batch, dtype=torch.float32)\n",
        "\n",
        "        num_correct += rewards_batch_tensor.sum()\n",
        "\n",
        "        # Unsqueeze to ensure rewards_batch_t has the same shape as targets_batch_t for element-wise ops SHAPE:(1, batch_size)\n",
        "        rewards_batch_t = rewards_batch_tensor.unsqueeze(1)\n",
        "\n",
        "        # --- START OF ADVANTAGE CALCULATION ---\n",
        "        # Calculate the mean of the rewards in the current batch\n",
        "        mean_reward = rewards_batch_tensor.mean()\n",
        "\n",
        "        # Calculate the standard deviation of the rewards in the current batch\n",
        "        # Add a small epsilon (1e-8) to prevent division by zero in case all rewards are identical\n",
        "        std_reward = rewards_batch_tensor.std() + 1e-8\n",
        "\n",
        "        # Calculate the advantage for each time step in the batch using your specified formula\n",
        "        advantages_of_batch = (rewards_batch_t - mean_reward) / (std_reward)\n",
        "        # --- END OF ADVANTAGE CALCULATION ---\n",
        "\n",
        "        mean_advantage_of_batch = advantages_of_batch.mean()\n",
        "\n",
        "        # Back propagation\n",
        "        loss = loss_fn(prediction_batch_tensor, targets_batch_tensor) * (1-mean_advantage_of_batch)\n",
        "        # Effect: If the batch had a very high advantage (meaning the model performed very well), the effective loss becomes very small, essentially telling the model it's doing great and its current parameters are good. This aligns with reinforcement\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Epoch count\n",
        "        if epoch % 1000 == 0:\n",
        "            print(f\"Epoch {epoch}: Loss = {loss.item()}, Reward = {reward}\")\n",
        "\n",
        "    print(\"Training completed.\\n\")\n",
        "    print(f\"Number of correct predictions: {num_correct}/{epochs * batch_size}\")\n",
        "    print(f\"Accuracy: {num_correct/(epochs * batch_size)}\",)\n",
        "\n",
        "    print(\"\\nTesting model:\")\n",
        "    for i in range(4):\n",
        "        pred = net(env.data[i]).item()\n",
        "        print(f\"Input: {env.data[i].tolist()}, Prediction: {round(pred)}, Actual: {env.targets[i].item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVsyQrc6N31_",
        "outputId": "3c2f47eb-a15a-4e79-8860-9e7a884d7e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training XNOR gate with 1000 epochs, 0.01 learning rate, and 10 batch size.\n",
            "Epoch 0: Loss = 0.22494681179523468, Reward = 1.0\n",
            "Training completed.\n",
            "\n",
            "Number of correct predictions: 9588.0/10000\n",
            "Accuracy: 0.9588000178337097\n",
            "\n",
            "Testing model:\n",
            "Input: [0.0, 0.0], Prediction: 1, Actual: 1.0\n",
            "Input: [0.0, 1.0], Prediction: 0, Actual: 0.0\n",
            "Input: [1.0, 0.0], Prediction: 0, Actual: 0.0\n",
            "Input: [1.0, 1.0], Prediction: 1, Actual: 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run training\n",
        "train_logic_gate(\"XNOR\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "AirQuality",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
